{
  "hash": "98f0534d746ccc24575eddf4e55913e8",
  "result": {
    "markdown": "---\ntitle: \"How rsample keeps memory usage low\"\ndescription: \"Copy-on-modify is pretty neat.\"\nauthor:\n  - name: Mike Mahoney\n    url: {}\ndate: \"2022-10-04\"\ncategories: [\"R\", \"rsample\", \"tidymodels\"]\nimage: splash.jpg\nformat: \n  html:\n    toc: true\nengine: knitr\n---\n\n\nA few months back, I wrote two comments on [a GitHub issue](https://github.com/tidymodels/rsample/issues/335) explaining a bit of how [rsample](https://rsample.tidymodels.org/) works under the hood. Specifically, a user asked how rsample keeps the total amount of memory that its resamples use relatively low. I've sent this GitHub issue to a few people since then, so it felt like it might be useful enough to turn the issue into a blog.^[Plus, I've been writing my candidacy exam for two weeks now, and need an excuse to look at anything else for an hour.]\n\n## What's an rsample?\n\nIn case you've never used it, [rsample](https://rsample.tidymodels.org/) is an R package for data resampling -- if you need bootstrap resampling, V-fold cross-validation, permutation sampling, and more, rsample is meant for you.^[For what it's worth, while I'm an author on rsample, I didn't write any of the rsample features mentioned in this blog post. I believe the rsample-specific details were all written by Max Kuhn. All the copy-on-modify semantics stuff, however, is just part of R and written over the past few decades by R Core.] The majority of these rsample functions return `rset` objects, which are just jazzed-up tibbles:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nlibrary(rsample)\nlibrary(mlbench)\ndata(LetterRecognition)\n\nboots <- bootstraps(LetterRecognition, times = 2)\nboots\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Bootstrap sampling \n# A tibble: 2 × 2\n  splits               id        \n  <list>               <chr>     \n1 <split [20000/7403]> Bootstrap1\n2 <split [20000/7375]> Bootstrap2\n```\n:::\n:::\n\n\nEach of our individual resamples is stored as an `rsplit` object, each of which takes up a row in the `splits` column. Printing these objects tells us how many rows are in our analysis and assessment sets,^[\"Analysis\" maps to \"training\" while \"assessment\" maps to \"testing\". \"Analysis\" and \"assessment\" are purposefully used to [avoid confusion over _which_ training and test set are being used](https://www.tmwr.org/resampling.html#resampling-methods).] but hides most of the actual structure of the `rsplit` object. If we use `str()` instead, we can see that there are three named elements in each `rsplit`: `data`, our original data frame; `in_id`, which has the indices for which observations are going to be held \"in\" our analysis set, and `out_id`, which sometimes^[We'll come back to this.] has the indices for which observations are going to be held \"out\" to make up our assessment set, but here is `NA`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboots$splits[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n<Analysis/Assess/Total>\n<20000/7403/20000>\n```\n:::\n\n```{.r .cell-code}\nstr(\n  boots$splits[[1]]\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nList of 4\n $ data  :'data.frame':\t20000 obs. of  17 variables:\n  ..$ lettr: Factor w/ 26 levels \"A\",\"B\",\"C\",\"D\",..: 20 9 4 14 7 19 2 1 10 13 ...\n  ..$ x.box: num [1:20000] 2 5 4 7 2 4 4 1 2 11 ...\n  ..$ y.box: num [1:20000] 8 12 11 11 1 11 2 1 2 15 ...\n  ..$ width: num [1:20000] 3 3 6 6 3 5 5 3 4 13 ...\n  ..$ high : num [1:20000] 5 7 8 6 1 8 4 2 4 9 ...\n  ..$ onpix: num [1:20000] 1 2 6 3 1 3 4 1 2 7 ...\n  ..$ x.bar: num [1:20000] 8 10 10 5 8 8 8 8 10 13 ...\n  ..$ y.bar: num [1:20000] 13 5 6 9 6 8 7 2 6 2 ...\n  ..$ x2bar: num [1:20000] 0 5 2 4 6 6 6 2 2 6 ...\n  ..$ y2bar: num [1:20000] 6 4 6 6 6 9 6 2 6 2 ...\n  ..$ xybar: num [1:20000] 6 13 10 4 6 5 7 8 12 12 ...\n  ..$ x2ybr: num [1:20000] 10 3 3 4 5 6 6 2 4 1 ...\n  ..$ xy2br: num [1:20000] 8 9 7 10 9 6 6 8 8 9 ...\n  ..$ x.ege: num [1:20000] 0 2 3 6 1 0 2 1 1 8 ...\n  ..$ xegvy: num [1:20000] 8 8 7 10 7 8 8 6 6 1 ...\n  ..$ y.ege: num [1:20000] 0 4 3 2 5 9 7 2 1 1 ...\n  ..$ yegvx: num [1:20000] 8 10 9 8 10 7 10 7 7 8 ...\n $ in_id : int [1:20000] 18847 18895 2986 1842 3371 11638 4761 6746 16128 2757 ...\n $ out_id: logi NA\n $ id    : tibble [1 × 1] (S3: tbl_df/tbl/data.frame)\n  ..$ id: chr \"Bootstrap1\"\n - attr(*, \"class\")= chr [1:2] \"boot_split\" \"rsplit\"\n```\n:::\n:::\n\n\n## The mystery of the missing MBs\n\nSo, just looking at this structure, it seems like each `rsplit` contains a complete copy of our original data. But somehow, to borrow the example from the rsample README, creating a 50-times bootstrap sample doesn't require 50 times as much memory, but instead about 3x:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(LetterRecognition)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.64 MB\n```\n:::\n\n```{.r .cell-code}\nset.seed(35222)\nboots <- bootstraps(LetterRecognition, times = 50)\nlobstr::obj_size(boots)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n6.69 MB\n```\n:::\n:::\n\n\nEven that top-line result is a little misleading, though, because rsample isn't copying the data to actually create `boots`. If we look at the object sizes for both the original data and the resamples together, we can see that `boots` is only contributing ~4 MB:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(LetterRecognition, boots)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n6.69 MB\n```\n:::\n\n```{.r .cell-code}\nlobstr::obj_sizes(LetterRecognition, boots)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n* 2.64 MB\n* 4.04 MB\n```\n:::\n:::\n\n\nSo: what? How?\n\n## Copying; modifying\n\nWell, R uses what's known as [copy-on-modify](https://adv-r.hadley.nz/names-values.html) semantics. That means that, when you assign the same data to multiple variables, each of those variables will actually point at the same address in RAM:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLetterRecognition2 <- LetterRecognition\n\nlobstr::obj_addr(LetterRecognition)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x5573114c93e0\"\n```\n:::\n\n```{.r .cell-code}\nlobstr::obj_addr(LetterRecognition2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"0x5573114c93e0\"\n```\n:::\n\n```{.r .cell-code}\nidentical(\n  lobstr::obj_addr(LetterRecognition),\n  lobstr::obj_addr(LetterRecognition2)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nThis also means that `LetterRecognition2` takes up literally 0 space in your RAM:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(LetterRecognition, LetterRecognition2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n2.64 MB\n```\n:::\n:::\n\n\nAnd that will stay true up until we modify either of these objects. No copy is made, no additional RAM gets used, until one of the objects is modified.\n\nThat also means that, right now, `LetterRecognition2` is another name for the data stored in each of our `rsplits`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nidentical(\n  lobstr::obj_addr(boots$splits[[1]]$data),\n  lobstr::obj_addr(LetterRecognition2)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n:::\n\n\nAnd if we get rid of `LetterRecognition`, which both `LetterRecognition2` and our bootstraps are based off of, those objects will _still_ point at the same address,^[As of [R 4.0](https://stat.ethz.ch/pipermail/r-announce/2020/000653.html), as I understand it.] and our `data` slot in `boots` still won't take up additional space:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm(LetterRecognition)\ngc()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n          used (Mb) gc trigger (Mb) max used (Mb)\nNcells  849739 45.4    1358681 72.6  1358681 72.6\nVcells 2362850 18.1    8388608 64.0  8384745 64.0\n```\n:::\n\n```{.r .cell-code}\nidentical(\n  lobstr::obj_addr(boots$splits[[1]]$data),\n  lobstr::obj_addr(LetterRecognition2)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] TRUE\n```\n:::\n\n```{.r .cell-code}\nlobstr::obj_sizes(LetterRecognition2, boots$splits[[1]]$data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n* 2.64 MB\n*     0 B\n```\n:::\n:::\n\n\nSo how does rsample keep its objects so small? By not making extra copies of your data where it doesn't have to. This is how the entire `boots` table winds up only adding ~1.5x the space of the original data:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_sizes(LetterRecognition2, boots)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n* 2.64 MB\n* 4.04 MB\n```\n:::\n:::\n\n\nAnd that's pretty close to as small as this object could get -- that's just the amount of space required to store the indices (in this case, 20,000 indices per repeat, 50 repeats):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(sample.int(20000 * 50))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n4.00 MB\n```\n:::\n:::\n\n\n(The 42kb difference is the attributes we've attached to each split -- things like its class and ID and so on -- but that's not going to be enough memory to be relevant for most applications.)\n\nThis is also, as it happens, why `out_id` is set `NA` in our bootstrap resamples.^[Told ya we'd come back to it.] Because you can figure out which observations we want to \"hold out\" for the assessment set based on which ones we're keeping \"in\" for analysis, rsample doesn't store those indices for most of its resampling methods.^[Now the package I maintain, spatialsample, _does_ include `out_id` on its objects relatively often. Most of the time, this is because the objects were created with a non `NULL` buffer, and so our hold out set isn't simply \"all of the data that's not in\"; sometimes it's because I initially _always_ included `out_id`, and haven't fixed my code to be more efficient yet. PRs welcome!]\n\nAnd one last thought: if you modified `LetterRecognition2`, _then_ the data in our splits would no longer point at the same address space as the original table. That's entirely on purpose and desirable, because once you start messing with your original data, your resampling indices are no longer guaranteed to correspond to the original table you used to create them.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nLetterRecognition2 <- NA\n\nidentical(\n  lobstr::obj_addr(boots$splits[[1]]$data),\n  lobstr::obj_addr(LetterRecognition2)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] FALSE\n```\n:::\n:::\n\n\nBut, as best as possible, rsample will keep the `rset` small.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlobstr::obj_size(boots)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n6.69 MB\n```\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}